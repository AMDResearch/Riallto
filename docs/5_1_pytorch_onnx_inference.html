<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Run Machine Learning Inference on the NPU with Pytorch and ONNX &mdash; AMD Riallto 1.0 documentation</title><link rel="icon" type="image/x-icon" href="_static/favicon.ico">
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="_static/./custom.css" type="text/css" />
      <link rel="stylesheet" href="_static/./custom_page_width.css" type="text/css" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/orestbida/cookieconsent@v3.0.0-rc.17/dist/cookieconsent.css">
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/documentation_options.js?v=2882ecd3"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="_static/copybutton.js?v=f281be69"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/jquery.js"></script>
    <script src="_static/cookie-consent.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Pytorch and ONNX Flow for Training" href="5_2_pytorch_onnx_re-train.html" />
    <link rel="prev" title="Reusing Software Kernels" href="4_8_build_a_colorDetect_application.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JK8T9PJNL0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-JK8T9PJNL0');
</script>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="index.html" class="icon icon-home"> AMD Riallto
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Home</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Riallto overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="1_0_Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-riallto.html">Install Riallto</a></li>
<li class="toctree-l1"><a class="reference internal" href="ryzenai_video_overview.html">Riallto Video Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_1_ryzenai.html">Ryzen AI Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_1_MS_Windows_Studio_Effects.html">Windows Studio Effects</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NPU Architecture examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="3_1_Color_threshold_example.html">Loading your first example</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_2_Ryzenai_capabilities.html">Understanding columns and tiles</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_3_Scaled_color_threshold_example.html">Scaling applications to multiple compute tiles</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_4_Edge_detect_example.html">Optimizing data movement</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_5_Color_detect_example.html">Multicasting and multiple kernels per tile</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Building applications</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="4_1_software_framework.html">Introduction to the Riallto software framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_2_write_your_kernel.html">Write your first kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_3_kernels_with_runtime_parameters.html">Using Run Time Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_4_threshold_kernel_with_vector_ops.html">How to use the vector processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_5_describe_an_application.html">Describing an application</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_6_build_application.html">Building a complete application</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_7_using_the_memtile_in_your_applications.html">Using memory tiles</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_8_build_a_colorDetect_application.html">Reusing software kernels</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Ryzen AI Machine Learning</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Inference with PyTorch and ONNX</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Goals">Goals</a></li>
<li class="toctree-l2"><a class="reference internal" href="#References">References</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Ryzen-AI-Software-Platform">Ryzen AI Software Platform</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Step-1:-Import-Packages">Step 1: Import Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Step-2:-Prepare-the-Data">Step 2: Prepare the Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Download-the-CIFAR-10-dataset">Download the CIFAR-10 dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Step-3:-Deploy-the-Model-on-the-NPU">Step 3: Deploy the Model on the NPU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Load-quantized-ONNX-model">Load quantized ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Deploy-the-quantized-ONNX-model-on-the-Ryzen-AI-NPU">Deploy the quantized ONNX model on the Ryzen AI NPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Inference">Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Inference-for-more-test-images">Inference for more test images</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Confusion-matrix">Confusion matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Accuracy-of-the-quantized-model-for-5,000-test-images">Accuracy of the quantized model for 5,000 test images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Step-4:-Deploy-the-Model-on-CPU">Step 4: Deploy the Model on CPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Delete-all-Extracted-Images">Delete all Extracted Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Licenses">Licenses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="5_2_pytorch_onnx_re-train.html">Re-training with PyTorch and ONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python Package</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">npu</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Riallto FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Glossary</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Appendix_Review_of_Image_Processing_Concepts.html">Review of Image Processing concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites-driver.html">Install the NPU driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites-aie-license.html">Get an AIE license</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites-wsl.html">Enable WSL</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AMD Riallto</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Run Machine Learning Inference on the NPU with Pytorch and ONNX</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Run-Machine-Learning-Inference-on-the-NPU-with-Pytorch-and-ONNX">
<h1>Run Machine Learning Inference on the NPU with Pytorch and ONNX<a class="headerlink" href="#Run-Machine-Learning-Inference-on-the-NPU-with-Pytorch-and-ONNX" title="Link to this heading">¶</a></h1>
<section id="Goals">
<h2>Goals<a class="headerlink" href="#Goals" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>Introduce the Ryzen™ AI Software Platform</p></li>
<li><p>Show the ONNX model generation and inference flow on the NPU</p></li>
<li><p>Deploy a quantized ResNet-50 model onto Ryzen AI NPU for inference</p></li>
</ul>
</section>
<section id="References">
<h2>References<a class="headerlink" href="#References" title="Link to this heading">¶</a></h2>
<p><a class="reference external" href="https://ryzenai.docs.amd.com/en/latest/getstartex.html">Ryzen AI Software Platform</a></p>
<p><a class="reference external" href="https://onnxruntime.ai/docs/execution-providers/Vitis-AI-ExecutionProvider.html">Vitis AI Execution Provider</a></p>
<p><a class="reference external" href="https://matplotlib.org/stable/gallery/axes_grid1/simple_axesgrid.html">Matplotlib Gallery</a></p>
<p><a class="reference external" href="https://github.com/EN10/CIFAR">CIFAR10</a></p>
<p><a class="reference external" href="https://christianbernecker.medium.com/how-to-create-a-confusion-matrix-in-pytorch-38d06a7f04b7">Confusion Matrix</a></p>
<hr class="docutils" />
</section>
<section id="Ryzen-AI-Software-Platform">
<h2>Ryzen AI Software Platform<a class="headerlink" href="#Ryzen-AI-Software-Platform" title="Link to this heading">¶</a></h2>
<p>The AMD Ryzen™ AI Software Platform enables developers to take machine learning models trained in PyTorch or TensorFlow and run them on laptops powered by Ryzen AI. The Ryzen AI software platform intelligently optimizes tasks and workloads, freeing-up CPU and GPU resources, and ensuring optimal performance at lower power. The diagram below shows the flow from trained models to execution.</p>
<center><p><img alt="sdk" src="_images/ryzen-ai-sdk.png" /></p>
</center><center><p>Ryzen AI software platform</p>
</center><hr class="docutils" />
</section>
<section id="Step-1:-Import-Packages">
<h2>Step 1: Import Packages<a class="headerlink" href="#Step-1:-Import-Packages" title="Link to this heading">¶</a></h2>
<p>Run the following cell to import all the necessary packages to be able to run the inference in the Ryzen AI NPU.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span> <span class="k">as</span> <span class="nn">ort</span>

<span class="kn">import</span> <span class="nn">enum</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">ImageGrid</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sn</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
</section>
<section id="Step-2:-Prepare-the-Data">
<h2>Step 2: Prepare the Data<a class="headerlink" href="#Step-2:-Prepare-the-Data" title="Link to this heading">¶</a></h2>
<p>We are going to use a pre-trained ResNet-50 model from PyTorch Hub for the CIFAR-10 dataset.</p>
<section id="Download-the-CIFAR-10-dataset">
<h3>Download the CIFAR-10 dataset<a class="headerlink" href="#Download-the-CIFAR-10-dataset" title="Link to this heading">¶</a></h3>
<p>Execute the following cells to download the CIFAR-10 dataset. The dataset is stored in <code class="docutils literal notranslate"><span class="pre">data/cifar-10-batches-py/</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">global</span> <span class="n">models_dir</span><span class="p">,</span> <span class="n">data_dir</span>
<span class="n">models_dir</span> <span class="o">=</span> <span class="s2">&quot;.</span><span class="se">\\</span><span class="s2">onnx&quot;</span>
<span class="n">data_dir</span><span class="o">=</span> <span class="s2">&quot;.</span><span class="se">\\</span><span class="s2">onnx</span><span class="se">\\</span><span class="s2">data&quot;</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># License 1 (see end of notebook)</span>

<span class="c1"># Download data - One-time only</span>

<span class="n">datadirname</span> <span class="o">=</span> <span class="s2">&quot;.</span><span class="se">\\</span><span class="s2">onnx</span><span class="se">\\</span><span class="s2">data&quot;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">datadirname</span><span class="p">):</span>
   <span class="n">data_download_tar</span> <span class="o">=</span> <span class="s2">&quot;cifar-10-python.tar.gz&quot;</span>
   <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="s2">&quot;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&quot;</span><span class="p">,</span> <span class="n">data_download_tar</span><span class="p">)</span>
   <span class="n">file</span> <span class="o">=</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">data_download_tar</span><span class="p">)</span>
   <span class="n">file</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
   <span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Delete cifar-10-python.tar.gz source file after all images are extracted</span>
<span class="n">data_images_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;cifar-10-python.tar.gz&quot;</span><span class="p">)</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">data_images_path</span><span class="p">)</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="line-block">
<div class="line">The <a class="reference external" href="https://github.com/EN10/CIFAR">CIFAR-10</a> dataset has 60,000 32x32 pixels color images in 10 classes, each class consists of 6,000 images. There are 50,000 training images and 10,000 test images.</div>
<div class="line">The dataset contains five training batches and one test batch, 10,000 images in each. Each class in the test batch has 1,000 randomly selected images.</div>
</div>
<div class="alert alert-box alert-info"><p>For inference we use the 10,000 test images.</p>
</div><p>The CIFAR10 classes are enumerated in the <code class="docutils literal notranslate"><span class="pre">Cifar10Classes</span></code> class below:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Cifar10Classes</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">airplane</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">automobile</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">bird</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">cat</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">deer</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">dog</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">frog</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">horse</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="n">ship</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">truck</span> <span class="o">=</span> <span class="mi">9</span>
</pre></div>
</div>
</div>
<p>Run the following two cells to display a subset of the test images.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># License 2 (see end of notebook)</span>

<span class="k">def</span> <span class="nf">unpickle</span><span class="p">(</span><span class="n">file</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fo</span><span class="p">:</span>
        <span class="nb">dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fo</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin1&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span>

<span class="n">datafile</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;./onnx/data/cifar-10-batches-py/test_batch&#39;</span>
<span class="n">metafile</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;./onnx/data/cifar-10-batches-py/batches.meta&#39;</span>

<span class="n">test_batch</span> <span class="o">=</span> <span class="n">unpickle</span><span class="p">(</span><span class="n">datafile</span><span class="p">)</span>
<span class="n">metadata</span> <span class="o">=</span> <span class="n">unpickle</span><span class="p">(</span><span class="n">metafile</span><span class="p">)</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">test_batch</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">test_batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">images</span><span class="p">,(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

<span class="n">im</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">dirname</span> <span class="o">=</span> <span class="s1">&#39;onnx/onnx_test_images&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dirname</span><span class="p">):</span>
   <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">dirname</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">im</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">))</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">ImageGrid</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="mi">111</span><span class="p">,</span>  <span class="c1"># similar to subplot(111)</span>
                 <span class="n">nrows_ncols</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>  <span class="c1"># creates 4x5 grid of axes</span>
                 <span class="n">axes_pad</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>  <span class="c1"># pad between axes in inch.</span>
                 <span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Actual label: </span><span class="si">{</span><span class="n">Cifar10Classes</span><span class="p">(</span><span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span><span class="mi">8</span><span class="p">})</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/5_1_pytorch_onnx_inference_17_0.png" src="_images/5_1_pytorch_onnx_inference_17_0.png" />
</div>
</div>
<hr class="docutils" />
</section>
</section>
<section id="Step-3:-Deploy-the-Model-on-the-NPU">
<h2>Step 3: Deploy the Model on the NPU<a class="headerlink" href="#Step-3:-Deploy-the-Model-on-the-NPU" title="Link to this heading">¶</a></h2>
<p>Run the next cell to set up the <code class="docutils literal notranslate"><span class="pre">XLNX_VART_FIRMWARE</span></code> environmental variable to point to the NPU binary. The NPU binary <code class="docutils literal notranslate"><span class="pre">1x4.xclbin</span></code> is an AI design that provides up to 2 TOPS performance. up to four such AI streams can be run in parallel on the NPU without any visible loss of performance.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1x4 array</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;XLNX_VART_FIRMWARE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;xclbins&quot;</span><span class="p">,</span><span class="s2">&quot;1x4.xclbin&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Load-quantized-ONNX-model">
<h3>Load quantized ONNX model<a class="headerlink" href="#Load-quantized-ONNX-model" title="Link to this heading">¶</a></h3>
<p>Run the following cell to load the provided ONNX quantized model.</p>
<div class="alert alert-box alert-info"><p>We will use the following pre-trained quantized file:</p>
<ul class="simple">
<li><p>The trained quantized ResNet-50 model on the CIFAR-10 dataset is saved at the following location: <code class="docutils literal notranslate"><span class="pre">onnx/resnet.qdq.U8S8.onnx</span></code></p></li>
</ul>
<p>If you would like to re-train and quantize your model, please review the <a class="reference internal" href="5_2_pytorch_onnx_re-train.html"><span class="doc">Pytorch_ONNX_re-train</span></a> notebook.</p>
</div><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># License 2 (see end of notebook)</span>

<span class="n">quantized_model_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;./onnx/resnet.qdq.U8S8.onnx&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">quantized_model_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Deploy-the-quantized-ONNX-model-on-the-Ryzen-AI-NPU">
<h3>Deploy the quantized ONNX model on the Ryzen AI NPU<a class="headerlink" href="#Deploy-the-quantized-ONNX-model-on-the-Ryzen-AI-NPU" title="Link to this heading">¶</a></h3>
<p>For more information on provider options visit <a class="reference external" href="https://ryzenai.docs.amd.com/en/latest/modelrun.html">ONNX Runtime with Vitis AI Execution Provider</a></p>
<div class="alert alert-box alert-info"><p>The file <code class="docutils literal notranslate"><span class="pre">onnx/vaip_config.json</span></code> is required when configuring Vitis AI Execution Provider (VAI EP) inside the ONNX Runtime code.</p>
</div><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># License 2 (see end of notebook)</span>

<span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;VitisAIExecutionProvider&#39;</span><span class="p">]</span>
<span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;onnx&quot;</span><span class="p">)</span>
<span class="n">provider_options</span> <span class="o">=</span> <span class="p">[{</span>
            <span class="s1">&#39;config_file&#39;</span><span class="p">:</span> <span class="s1">&#39;onnx/xclbins/vaip_config.json&#39;</span><span class="p">,</span>
            <span class="s1">&#39;cacheDir&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">),</span>
            <span class="s1">&#39;cacheKey&#39;</span><span class="p">:</span> <span class="s1">&#39;modelcachekey&#39;</span>
        <span class="p">}]</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">providers</span><span class="o">=</span><span class="n">providers</span><span class="p">,</span>
                               <span class="n">provider_options</span><span class="o">=</span><span class="n">provider_options</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
EP Error [json.exception.parse_error.101] parse error at line 1, column 1: syntax error while parsing value - unexpected end of input; expected &#39;[&#39;, &#39;{&#39;, or a literal when using [&#39;VitisAIExecutionProvider&#39;]
Falling back to [&#39;CPUExecutionProvider&#39;] and retrying.
</pre></div></div>
</div>
</section>
<section id="Inference">
<h3>Inference<a class="headerlink" href="#Inference" title="Link to this heading">¶</a></h3>
<p>The first 20 images are extracted from the CIFAR-10 test dataset and converted to the .png format.</p>
<p>The .png images are read, classified and visualized by running the quantized ResNet-50 model on the NPU.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># License 2 (see end of notebook)</span>

<span class="c1"># Extract and dump first 20 images</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">im</span>  <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">im</span><span class="p">,</span><span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>
    <span class="n">im_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;./</span><span class="si">{</span><span class="n">dirname</span><span class="si">}</span><span class="s1">/image_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">.png&#39;</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">im_name</span><span class="p">,</span> <span class="n">im</span><span class="p">)</span>

<span class="n">viz_predicted_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">misclassified_images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">misclassified_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">show_imlist</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Pick dumped images and predict</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">image_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;./</span><span class="si">{</span><span class="n">dirname</span><span class="si">}</span><span class="s1">/image_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">.png&#39;</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_name</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
    <span class="c1"># Resize the image to match the input size expected by the model</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">image_array</span><span class="o">/</span><span class="mi">255</span>

    <span class="c1"># Reshape the array to match the input shape expected by the model</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image_array</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Add a batch dimension to the input image</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Run the model</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="n">input_data</span><span class="p">})</span>

    <span class="c1"># Process the outputs</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;label_names&#39;</span><span class="p">][</span><span class="n">predicted_class</span><span class="p">]</span>
    <span class="n">viz_predicted_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;label_names&#39;</span><span class="p">][</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="c1"># print(f&#39;Image {i}: Actual Label {label}, Predicted Label {predicted_label}&#39;)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">label</span> <span class="o">!=</span> <span class="n">predicted_label</span><span class="p">):</span>
        <span class="n">misclassified_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">misclassified_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_label</span><span class="p">)</span>

    <span class="n">show_imlist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">))</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">ImageGrid</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="mi">111</span><span class="p">,</span>  <span class="c1"># similar to subplot(111)</span>
                 <span class="n">nrows_ncols</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>  <span class="c1"># creates 4x5 grid of axes</span>
                 <span class="n">axes_pad</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>  <span class="c1"># pad between axes in inch.</span>
                 <span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">show_imlist</span><span class="p">,</span> <span class="n">viz_predicted_labels</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Predicted label: </span><span class="si">{</span><span class="n">Cifar10Classes</span><span class="p">(</span><span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span><span class="mi">8</span><span class="p">})</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/5_1_pytorch_onnx_inference_27_0.png" src="_images/5_1_pytorch_onnx_inference_27_0.png" />
</div>
</div>
<p>Display the misclassifications</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show_imlist_mis</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">misclassified_images</span><span class="p">:</span>
    <span class="n">show_imlist_mis</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">))</span>

<span class="n">varpltsize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">misclassified_images</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">((</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">varpltsize</span><span class="p">),</span> <span class="mi">1</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">varpltsize</span><span class="p">))</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">ImageGrid</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="mi">111</span><span class="p">,</span>  <span class="c1"># similar to subplot(111)</span>
                 <span class="n">nrows_ncols</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">misclassified_images</span><span class="p">)),</span>
                 <span class="n">axes_pad</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>  <span class="c1"># pad between axes in inch.</span>
                 <span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">show_imlist_mis</span><span class="p">,</span> <span class="n">misclassified_labels</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Predicted label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span><span class="mi">8</span><span class="p">})</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/5_1_pytorch_onnx_inference_29_0.png" src="_images/5_1_pytorch_onnx_inference_29_0.png" />
</div>
</div>
</section>
<section id="Inference-for-more-test-images">
<h3>Inference for more test images<a class="headerlink" href="#Inference-for-more-test-images" title="Link to this heading">¶</a></h3>
<div class="alert alert-box alert-warning"><p>Note: the cell below may extract up to 5,000 images. You can delete the extracted images by following the instructions in Delete all Extracted Images.</p>
</div><div class="line-block">
<div class="line">The first 5,000 images are extracted from the CIFAR-10 test dataset and converted to the .png format.</div>
<div class="line">The .png images are read, classified and visualized by running the quantized ResNet-50 model on the NPU.</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># License 2 (see end of notebook)</span>

<span class="n">max_images</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span> <span class="c1"># 5000 test images</span>

<span class="c1"># Extract and dump all images in the test set</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_images</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">im</span>  <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">im</span><span class="p">,</span><span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>
    <span class="n">im_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;./</span><span class="si">{</span><span class="n">dirname</span><span class="si">}</span><span class="s1">/image_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">.png&#39;</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">im_name</span><span class="p">,</span> <span class="n">im</span><span class="p">)</span>

<span class="n">cm_predicted_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">cm_actual_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Pick dumped images and predict</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_images</span><span class="p">):</span>
    <span class="n">image_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;./</span><span class="si">{</span><span class="n">dirname</span><span class="si">}</span><span class="s1">/image_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">.png&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_name</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Image </span><span class="si">{</span><span class="n">image_name</span><span class="si">}</span><span class="s2"> maybe locked moving on to next image&quot;</span><span class="p">)</span>
        <span class="k">continue</span>
    <span class="c1"># Resize the image to match the input size expected by the model</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">image_array</span><span class="o">/</span><span class="mi">255</span>

    <span class="c1"># Reshape the array to match the input shape expected by the model</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image_array</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Add a batch dimension to the input image</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Run the model</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="n">input_data</span><span class="p">})</span>

    <span class="c1"># Process the outputs</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;label_names&#39;</span><span class="p">][</span><span class="n">predicted_class</span><span class="p">]</span>
    <span class="n">cm_predicted_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;label_names&#39;</span><span class="p">][</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="n">cm_actual_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="k">990</span> == 0:
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Status: Running Inference on image </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">... Actual Label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">, Predicted Label: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Status: Running Inference on image 0... Actual Label: cat, Predicted Label: cat
Status: Running Inference on image 990... Actual Label: automobile, Predicted Label: automobile
Status: Running Inference on image 1980... Actual Label: truck, Predicted Label: automobile
Status: Running Inference on image 2970... Actual Label: dog, Predicted Label: cat
Status: Running Inference on image 3960... Actual Label: bird, Predicted Label: bird
Status: Running Inference on image 4950... Actual Label: bird, Predicted Label: bird
</pre></div></div>
</div>
</section>
<section id="Confusion-matrix">
<h3>Confusion matrix<a class="headerlink" href="#Confusion-matrix" title="Link to this heading">¶</a></h3>
<p>The X-axis represents the predicted class and the Y-axis represents the actual class.</p>
<p>The diagonal cells show true positives, they show how many instances of each class were correctly predicted by the model. The off-diagonal cells show instances where the predicted class did not match the actual class.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">cm_actual_labels</span><span class="p">,</span> <span class="n">cm_predicted_labels</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cf_matrix</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cf_matrix</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">Cifar10Classes</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">Cifar10Classes</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">));</span>
<span class="n">sn</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;PiYG&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/5_1_pytorch_onnx_inference_33_0.png" src="_images/5_1_pytorch_onnx_inference_33_0.png" />
</div>
</div>
</section>
<section id="Accuracy-of-the-quantized-model-for-5,000-test-images">
<h3>Accuracy of the quantized model for 5,000 test images<a class="headerlink" href="#Accuracy-of-the-quantized-model-for-5,000-test-images" title="Link to this heading">¶</a></h3>
<div class="alert alert-box alert-info"><p>The below accuracy on the test images is calculated for the quantized model run on the NPU.</p>
</div><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Accuracy of the quantized model for the test set is : </span><span class="si">{</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">cm_actual_labels</span><span class="p">,</span><span class="w"> </span><span class="n">cm_predicted_labels</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 Accuracy of the quantized model for the test set is : 78.72 %
</pre></div></div>
</div>
<hr class="docutils" />
</section>
</section>
<section id="Step-4:-Deploy-the-Model-on-CPU">
<h2>Step 4: Deploy the Model on CPU<a class="headerlink" href="#Step-4:-Deploy-the-Model-on-CPU" title="Link to this heading">¶</a></h2>
<p>Deploy the Quantized ONNX Model on CPU (default provider)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">]</span>
<span class="n">provider_options</span> <span class="o">=</span> <span class="p">[{}]</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">providers</span><span class="o">=</span><span class="n">providers</span><span class="p">,</span>
                               <span class="n">provider_options</span><span class="o">=</span><span class="n">provider_options</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># License 2 (see end of notebook)</span>

<span class="c1">#Pick dumped images and predict</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">image_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;./</span><span class="si">{</span><span class="n">dirname</span><span class="si">}</span><span class="s1">/image_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">.png&#39;</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_name</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
    <span class="c1"># Resize the image to match the input size expected by the model</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">image_array</span><span class="o">/</span><span class="mi">255</span>

    <span class="c1"># Reshape the array to match the input shape expected by the model</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image_array</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Add a batch dimension to the input image</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


    <span class="c1"># Run the model</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="n">input_data</span><span class="p">})</span>


    <span class="c1"># Process the outputs</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;label_names&#39;</span><span class="p">][</span><span class="n">predicted_class</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;label_names&#39;</span><span class="p">][</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Image </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">: Actual Label </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">, Predicted Label: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Image 0: Actual Label cat, Predicted Label: cat
Image 1: Actual Label ship, Predicted Label: ship
Image 2: Actual Label ship, Predicted Label: ship
Image 3: Actual Label airplane, Predicted Label: airplane
Image 4: Actual Label frog, Predicted Label: deer
Image 5: Actual Label frog, Predicted Label: frog
Image 6: Actual Label automobile, Predicted Label: automobile
Image 7: Actual Label frog, Predicted Label: frog
Image 8: Actual Label cat, Predicted Label: cat
Image 9: Actual Label automobile, Predicted Label: automobile
</pre></div></div>
</div>
<hr class="docutils" />
</section>
<section id="Delete-all-Extracted-Images">
<h2>Delete all Extracted Images<a class="headerlink" href="#Delete-all-Extracted-Images" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Delete all extracted images to save disk space</span>
<span class="n">images_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;onnx_test_images&quot;</span><span class="p">,</span><span class="s2">&quot;*&quot;</span><span class="p">)</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">images_path</span><span class="p">)</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">continue</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
</section>
<section id="Licenses">
<h2>Licenses<a class="headerlink" href="#Licenses" title="Link to this heading">¶</a></h2>
<p>License 1</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) Microsoft Corporation. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License.</span>
<span class="c1"># --------------------------------------------------------------------------</span>
</pre></div>
</div>
<p>License 2</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#################################################################################</span>
<span class="c1"># License</span>
<span class="c1"># Ryzen AI is licensed under `MIT License &lt;https://github.com/amd/ryzen-ai-documentation/blob/main/License&gt;`_ . Refer to the `LICENSE File &lt;https://github.com/amd/ryzen-ai-documentation/blob/main/License&gt;`_ for the full license text and copyright notice.</span>
</pre></div>
</div>
<hr class="docutils" />
<center><p>Copyright© 2023 AMD, Inc</p>
</center><center><p>SPDX-License-Identifier: MIT</p>
</center><script type="application/vnd.jupyter.widget-state+json">
{"state": {}, "version_major": 2, "version_minor": 0}
</script></section>
</section>


           </div>
          </div>
          
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="4_8_build_a_colorDetect_application.html" class="btn btn-neutral float-left" title="Reusing Software Kernels" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="5_2_pytorch_onnx_re-train.html" class="btn btn-neutral float-right" title="Pytorch and ONNX Flow for Training" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Advanced Micro Devices, Inc.
      <span class="lastupdated">Last updated on January 17, 2024.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div id="cookie-consent" class="cookie-consent">
    <p>This website uses cookies to ensure you get the best experience on our website. <a href="#" id="cookie-accept">Accept</a> | <a href="#" id="cookie-reject">Reject</a></p>
</div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>
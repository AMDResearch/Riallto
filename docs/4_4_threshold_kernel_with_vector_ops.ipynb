{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bd044d-2483-4d4d-9db6-219d505ef9cc",
   "metadata": {},
   "source": [
    "# How to Use the Vector Processing Units\n",
    "\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Introduce AI Engine vector operations within a user-defined kernel\n",
    "\n",
    "* Develop our first single instruction multiple data path (SIMD) application\n",
    "\n",
    "* Achieve better performance when changing the run-time parameters (RTPs) during application execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41950c5-e887-4275-9d2c-4ae37bfa2d5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "**[AIE API reference manual](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/)**\n",
    "\n",
    "**[Single Instruction Multiple Data (SIMD)](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data)**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f022153-5a5c-4f6a-8bf8-070150eb41dd",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "Vectorization is a technique that allows a computer processor to perform the same operation on multiple data elements simultaneously, using a single instruction. This is supported by the SIMD architecture of the AI Engines in the NPU compute tiles. [SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) stands for Single Instruction, Multiple Data.  \n",
    "\n",
    "A vector represents a collection of data elements of the same type. A SIMD instruction is a single instruction that is executed simultaneously on multiple data elements. In other words, it processes vectors using a single operation.\n",
    "\n",
    "Vectorization is the process of transforming scalar operations (operations on individual data elements) into vector operations (operations on vectors). Instead of processing one data element at a time, vectorization enables the CPU to work on a batch of data elements in parallel. This approach leverages parallelism to improve the computational efficiency of tasks that involve the same operations on a set of data, such as arrays or vectors.\n",
    "\n",
    "We will show how the benefits of SIMD data parallelism are achieved with the AI Engine's vector processor unit, shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72798159-e9a3-4b48-b91c-3e581c16ba32",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/png/ai_engine_processor.png\" style=\"max-height: 400px; width:auto; height:auto;\"></center>\n",
    "<center><strong>AIE-ML Architecture</strong></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326eaed-e40d-4e3f-9680-83d7a6c1a86a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "   The <em>vectorization factor</em> is the number of data lanes in the vector unit.  It corresponds to the number of scalar iterations that can be performed by each vector instruction. The vector processing unit (VPU) data path is 512-bits wide. It has 64 lanes for 8-bit data types, 32 lanes for 16-bit types or 16 lanes for 32-bit types. The VPU's vectorization factor is configurable to accommodate the different widths of different data types. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22fc571-a2a1-4441-97a5-8da68de728db",
   "metadata": {},
   "source": [
    "## Introduction to the AI Engine API\n",
    "\n",
    "The previous examples used C++ code with no special APIs. C/C++ have limited built in support for vector processing. We will use the AI Engine API which support the vector architecture of the processor.\n",
    "\n",
    "You can read more details in the [AIE API reference manual](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/)\n",
    "\n",
    "To get started we need to understand the load and store vector APIs, and the arithmetic vector APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ec060-1ccd-45bf-a1ab-3b7fa2490cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load/Store and Vector APIs\n",
    "\n",
    "Input and output data to software kernels running on AI Engines are stored in memory buffers in the local data memory of the compute tiles. Pointers provide the software kernel with access to the data buffers. On an AI Engine, the software kernel can read data from the input buffer pointer as a vector. This loads the inputs into special vector registers in the Vector Processing Unit. In the AI Engine, the output from the VPU is also stored in special vector registers, which can be written back to the output memory buffer as a vector.  \n",
    "\n",
    "The AI Engine VPU can perform up to two load and one store operations from local data memory per clock cycle. If you are unfamiliar with the terms load and store, a *load* is a read from memory, and a *store* is a write to memory. The data path for each of these load and store operations is 256-bit wide. This means we can load 512-bit of data and store 256-bit of data in one cycle.  \n",
    "\n",
    "We can use the following APIs to load and store vectors:\n",
    "\n",
    "* `::aie::load_v<N>(pointer)`: [AIE Store vector operator documentation](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/group__group__memory.html#ga1d143988d732069ef3c66dc6d2ae3ea9)\n",
    "  * loads a vector of `N` elements from the input `pointer` and returns a vector of `N` elements of the underlying type of `pointer`.\n",
    "\n",
    "* `::aie::store_v(pointer, vector)`: [AIE Store vector operator documentation](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/group__group__memory.html#gaa134a9db67641fc7ee69be78c7b00bf6)\n",
    "  * stores a `vector` into the buffer in data memory associated to the output `pointer`.\n",
    "\n",
    "We must use vector data types with these APIs. To declare a vector data type we can use the following:\n",
    "\n",
    "* `::aie::vector<<type>, <vector length>> vector_name`: [AIE vector data type documentation](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/group__group__basic__types.html#classaie_1_1vector)\n",
    "  * Creates a vector of the specified type and length\n",
    "\n",
    "You will see these APIs used in the next software kernel we will build. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156729a-6c4e-4fd0-aefd-eeb8a40ebd54",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "  Data should be 128-bit aligned to get maximum performance. Data aligned on different boundaries will not be loaded/stored in a single operation. \n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec66da-1dc6-4c8b-b2a5-03e3dc859e0c",
   "metadata": {},
   "source": [
    "## Operating on Vectors\n",
    "\n",
    "The AI Engine APIs support the following vector operations:\n",
    "\n",
    "- [Arithmetic](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/group__group__arithmetic.html) - E.g., adding, subtracting, multiplying, accumulating, bitwise. \n",
    "\n",
    "- [Comparison](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/group__group__compare.html) - E.g., less than, greater than, equals/not equals. \n",
    "\n",
    "- [Reduction](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/group__group__reduce.html) - E.g., reduction add, min, max.\n",
    "\n",
    "- [Reshaping](https://www.xilinx.com/htmldocs/xilinx2023_2/aiengine_api/aie_api/doc/group__group__reshape.html) - E.g., select, filter, interleave, shuffle. \n",
    "\n",
    "You can follow the links for more details, but this is not necessary at this stage. \n",
    "\n",
    "These APIs will be demonstrated in the software kernel code in the next examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853eed2-456e-45b5-a5fd-61f53abe88d3",
   "metadata": {},
   "source": [
    "## Vectorizing the pass-through Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b48ee-8a7d-421e-9ee4-e9a83f7c3970",
   "metadata": {},
   "source": [
    "To make a vectorized version of the pass-through application that we saw in earlier notebooks, we write the following C++ code:\n",
    "\n",
    "```c++\n",
    "void passthrough_vectorized(uint8_t *in_buffer, uint8_t *out_buffer, uint32_t nbytes){\n",
    "    // a buffer to temporarily store our vector\n",
    "    ::aie::vector<uint8_t, 64> buffer; \n",
    "\n",
    "    // divide by vectorization factor (64)\n",
    "    uint32_t loop_count = nbytes >> 6; \n",
    "    \n",
    "    for(int i=0; i<loop_count; i++) {\n",
    "        \n",
    "         // load 32 elements into the buffer\n",
    "        buffer = ::aie::load_v<64>(in_buffer);\n",
    "\n",
    "        // store buffer into the out buffer\n",
    "        ::aie::store_v<64>(out_buffer, buffer); \n",
    "\n",
    "         // We need to increment the buffers by 32 each iteration now\n",
    "        in_buffer += 64;\n",
    "        out_buffer += 64;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d77a19-2061-4c08-a1db-5e31f0e5d084",
   "metadata": {},
   "source": [
    "### Explaining the code\n",
    "\n",
    "The C++ code defines a function named `passthrough_vectorized()` that operates on arrays of 8-bit unsigned integers (uint8_t). Like the first passthrough example we saw, this function copies data from an input buffer to an output buffer in a vectorized manner, without any other processing. By vectorizing this example, it processes data in chunks of 64 elements at a time for improved performance.\n",
    "Breaking this code down line by line:\n",
    "\n",
    "#### Declare a vector\n",
    "```\n",
    "::aie::vector<uint8_t,64> buffer;\n",
    "```\n",
    "\n",
    "This line declares a vector named buffer, which can hold 64 elements of uint8_t type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b1264-2e67-4d1f-95a4-4318c362595f",
   "metadata": {},
   "source": [
    "#### Calculate the number of loop iterations\n",
    "\n",
    "```c++\n",
    "uint32_t loop_count = nbytes >> 6;\n",
    "```\n",
    "This line calculates the number of iterations required to process the data. It shifts the nbytes (number of bytes) to the right by 6 bits, effectively dividing it by 64 (2<sup>6</sup>). This determines how many 64-element chunks there are in the data to be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056546a-0d2b-478d-a016-a8047fe7556b",
   "metadata": {},
   "source": [
    "#### Create a loop and load input data\n",
    "```c++\n",
    "for(int i=0; i<loop_count; i++) {\n",
    "```\n",
    "\n",
    "This initiates a loop that will run loop_count times, with i as the loop counter\n",
    "\n",
    "```c++\n",
    "buffer = ::aie::load_v<64>(in_buffer);\n",
    "```\n",
    "\n",
    "Inside the loop, this line loads 64 elements from the in_buffer into the buffer. The load vectorized operation is provided by the ::aie:: library. It effectively copies 64-Byte from the data memory to one of the vector registers of the NPU array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18a108-f26b-459f-967f-7e611e37a960",
   "metadata": {},
   "source": [
    "#### Store the result\n",
    "\n",
    "```c++\n",
    "::aie::store_v<64>(out_buffer, buffer);\n",
    "```\n",
    "\n",
    "The input is loaded into a vector register in the VPU. For this *passthrough* software kernel, the input passes unmodified through the VPU. The ::aie::stores_v writes the result from the vector registers back to the output memory buffer. The store operation effectively copies the 64 elements from the VPU to the local data memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a951d-e2a5-4c3d-be0c-a76e63d8f9a7",
   "metadata": {},
   "source": [
    "#### Increment the counters\n",
    "\n",
    "```c++\n",
    "input_buffer += 64;\n",
    "output_buffer += 64;\n",
    "```\n",
    "\n",
    "After processing a chunk of 64-element, both buffer pointers are incremented by 64 to prepare for the next chunk of data.\n",
    "\n",
    "#### Vectorized software kernel conclusion\n",
    "\n",
    "The function continues the loop until it has processed all the data in nbytes. The use of vectorized operations allows load and store access and copying, as it operates on larger data chunks at a time. This will result in significant performance improvements compared to scalar processing (processing one element at a time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a03ac-5309-4837-a97f-36f081545815",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c5259-d652-49ae-8b2c-bb794a7b4796",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Writing a Vectorized Threshold Kernel\n",
    "\n",
    "Rather than build the simple passthrough kernel, we will go straight to a vectorized threshold kernel. \n",
    "\n",
    "The overall objective of a vectorized threshold kernel is to implement the same *threshold functionality* we saw in an earlier example, but parallelized so that it can process multiple pixels in each iteration. This will significantly reduce the time the kernel needs to iterate in its innermost loop, resulting in a noticeable speed-up.\n",
    "\n",
    "Each RGBA pixel is 4-Byte so we choose a vector data type of length 32-bit to represent each pixel in our compute tile.  Since our vector processing is 512-bit wide, we can now process 16 RGBA pixels per operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4358a7c-72d7-4b25-acfd-c27c8f10c45c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Start by importing the `npu` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580ea5a4-5b9a-4735-b92e-ede8ca3d04d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:13:29.074310Z",
     "iopub.status.busy": "2023-12-19T15:13:29.074310Z",
     "iopub.status.idle": "2023-12-19T15:13:30.474920Z",
     "shell.execute_reply": "2023-12-19T15:13:30.474920Z"
    }
   },
   "outputs": [],
   "source": [
    "import npu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c79728-4d98-4dc1-b166-03de18120c02",
   "metadata": {},
   "source": [
    "This kernel will have the same functionality as the kernel defined in the previous notebook but with vector operations replacing the scalar operations.\n",
    "\n",
    "The primary AI Engine API operations we will use are:\n",
    "\n",
    "| ::aie:: call   | Operation Performed  |\n",
    "| --------------------- | -------------------------------------- |\n",
    "| ::aie::load_v<>()  | Vector load  |\n",
    "| ::aie::store_v()   | Vector store  |\n",
    "| ::aie::broadcast<>()  | Replicate arg_1 in each data lane of vector in arg_2. We will use this to pass the RunTime 'threshold' parameter to each data lane  |\n",
    "| ::aie::zeros<>() | Create a vector of zeros with the specified number of lanes and data type |\n",
    "| ::aie::lt<>()  | Vector less than comparison |\n",
    "| ::aie::mask<>()  | Vector compare arg1 with arg2 with resulting Boolean mask in arg3  |\n",
    "| ::aie::select()  | Select arg1 or arg2 based on mask in arg3  |\n",
    "\n",
    "Let us look at the different portions of our kernel to explore how this works. The completed software kernel code is provided here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b9ef56-3850-4228-966c-857109c2edf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:13:30.474920Z",
     "iopub.status.busy": "2023-12-19T15:13:30.474920Z",
     "iopub.status.idle": "2023-12-19T15:13:30.490546Z",
     "shell.execute_reply": "2023-12-19T15:13:30.490546Z"
    }
   },
   "outputs": [],
   "source": [
    "%%kernel\n",
    "\n",
    "void threshold_vec(uint8_t *in_buffer, uint8_t *out_buffer,\n",
    "                   uint32_t nbytes,\n",
    "                   uint8_t r_threshold, uint8_t g_threshold, uint8_t b_threshold)\n",
    "{\n",
    "    // Vector lanes\n",
    "    const uint8_t vector_lanes = 64;\n",
    "    // Value of saturated pixels\n",
    "    const uint8_t saturated = 255;\n",
    "\n",
    "    // Declare 512-bit wide vectors\n",
    "    ::aie::vector<uint8_t, vector_lanes> input_pixels;\n",
    "    ::aie::vector<uint8_t, vector_lanes> output_pixels;\n",
    "    ::aie::vector<uint8_t, vector_lanes> threshold_vector;\n",
    "    ::aie::vector<uint8_t, vector_lanes> saturation_vector;\n",
    "    ::aie::vector<uint8_t, vector_lanes> zeros_vector = ::aie::zeros<uint8_t, 64>();\n",
    "\n",
    "    // Broadcast saturated value into all 64 lanes of saturation_vector\n",
    "    saturation_vector = ::aie::broadcast<uint8_t, vector_lanes>(saturated);\n",
    "\n",
    "    // Create a new uint32 for the pixel threshold values, and concatenate the RTP values \n",
    "    uint32_t pixel_rtps32;\n",
    "    pixel_rtps32 = (uint32_t)b_threshold << 16 | \n",
    "                   (uint32_t)g_threshold << 8 |\n",
    "                   (uint32_t)r_threshold;\n",
    "\n",
    "    // Broadcast threshold values into the kernel 32-bit at a time \n",
    "    threshold_vector =::aie::broadcast<uint32_t, 16>(pixel_rtps32).cast_to<uint8_t>();\n",
    "\n",
    "    // Vectorized thresholding loop\n",
    "    uint16_t loop_count = (nbytes) >> 6;  \n",
    "    for(int j=0; j<loop_count; j++) {\n",
    "\n",
    "        // Vector load pixels and mask\n",
    "        input_pixels = ::aie::load_v<vector_lanes>(in_buffer); \n",
    "\n",
    "        // Create 64-bit threshold status register\n",
    "        ::aie::mask<64> threshold_status;\n",
    "        // Capture Boolean results of thresholding\n",
    "        threshold_status = ::aie::lt(threshold_vector, input_pixels);\n",
    "\n",
    "        // Vector select actual pixel values using threshold_status as mask\n",
    "        output_pixels = ::aie::select(zeros_vector, saturation_vector, threshold_status);\n",
    "        // Vector store thresholded pixels in output buffer\n",
    "        ::aie::store_v(out_buffer, output_pixels);   \n",
    "\n",
    "        // Advance buffer pointers by vectorization factor\n",
    "        in_buffer += vector_lanes;\n",
    "        out_buffer += vector_lanes;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad902240",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15137be-11f4-47bd-8d3e-30155ab6a580",
   "metadata": {},
   "source": [
    "## Examining the Kernel\n",
    "\n",
    "The vectorized kernel code above looks different from those in the previous notebooks. It uses APIs from the AI Engine library `::aie` to perform vector operations. To explain this kernel, we are going to break it up into two main parts:\n",
    "\n",
    "1. The initialization, i.e., the bit before the for loop.\n",
    "2. The inner loop body, i.e., the bit inside the innermost loop.\n",
    "\n",
    "\n",
    "### Initialization\n",
    "\n",
    "The majority of the computation work that the kernel performs is within the innermost loop; however, before we can get to that, we need to set up some vectors that we are going to use within that inner loop. \n",
    "\n",
    "We start by defining some constants. The individual red, green and blue and alpha values of the pixel are 8-bit. We will use unsigned int8 as the vector data type so that we can operate on each pixel component. As the AI Engine datapath is 512-bit wide and supports 64 8-bit lanes, we define a constant for the number of lanes. Each pixel is 32-bit, so we will be able to process 16 pixels at a time. \n",
    "\n",
    "We will also define a `saturated` value we will set pixel components to if it exceeds the threshold. 255 is the maximum value for an unsigned int8. \n",
    "\n",
    "```c++\n",
    "    const uint8_t vector_lanes = 64;\n",
    "    const uint8_t saturated = 255;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609e031-0671-47ab-8209-cad0de14ed96",
   "metadata": {},
   "source": [
    "Next, we declare vectors for the input, output, a threshold vector, and a saturation vector. Each of these vectors is 512-bit wide (64 lanes x 8-bit). \n",
    "\n",
    "The `saturation_vector` will be used for the values that we want our pixels to be set to if they are over the threshold value. We will use the `threshold_vector` for the pixel-wise comparison in our inner loop. \n",
    "\n",
    "```c++\n",
    "    // Declare 512-bit wide vectors\n",
    "    ::aie::vector<uint8_t, vector_lanes> input_pixels;\n",
    "    ::aie::vector<uint8_t, vector_lanes> output_pixels;\n",
    "    ::aie::vector<uint8_t, vector_lanes> threshold_vector;\n",
    "    ::aie::vector<uint8_t, vector_lanes> saturation_vector;\n",
    "    ::aie::vector<uint8_t, vector_lanes> zeros_vector = ::aie::zeros<uint8_t, 64>();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb19424-b650-4c1a-b3cd-20b221febee3",
   "metadata": {},
   "source": [
    "The next line initializes the `saturation_vector`. This is done using the `::aie::broadcast()` function, which copies or broadcasts the saturated value into each lane of the vector. \n",
    "\n",
    "```c++\n",
    "    ::aie::vector<uint8_t, 64> saturation_vector = ::aie::broadcast<uint8_t, 64>(saturated);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2981d2d-9bad-4901-b207-4b8fc07e7a6f",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/png/sat_vec_broadcast.png\" style=\"max-width:70%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7b51f-d188-493e-b9f1-da93ff151a2e",
   "metadata": {},
   "source": [
    "The next lines create a 32-bit unsigned int which will store the combined values from the individual 8-bit RGBA components. The values are combined by shifting and using a bitwise OR. Red is bits 0-7, green is bits 8-15, and blue is bits 16-23. The alpha channel is bits 25-31 but is not used so ORing with 0x0 ensures these bits are set these bits to zero. \n",
    "\n",
    "```c++\n",
    "    uint32_t pixel_rtps32;\n",
    "    pixel_rtps32 = 0x0 |\n",
    "                   (uint32_t)b_threshold << 16 | \n",
    "                   (uint32_t)g_threshold << 8 |\n",
    "                   (uint32_t)r_threshold;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024f33a-4516-4a59-82a5-f37dd59fe766",
   "metadata": {},
   "source": [
    "The next line is a little complicated. We start from `pixel_rtps32` to create the `threshold_vector`.\n",
    "\n",
    "Broadcast will create a new temporary variable, and broadcast this to the `threshold_vector`. First, we broadcast 16x 32-bit combined RGBA values, but cast them back to uint8 types to fill the 64x 8-bit lanes of the threshold_vector. \n",
    "\n",
    "```c++\n",
    "    // Broadcast threshold values into %%kernel 32 bits at a time \n",
    "    threshold_vector =::aie::broadcast<uint32_t, 16>(pixel_rtps32).cast_to<uint8_t>();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c798d0f-9127-4eb6-82a5-af85ec5be89c",
   "metadata": {},
   "source": [
    "The `threshold_vector` vector will be compared with our input RGBA vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f17da-cd86-4b60-b81a-cf3f2571cac6",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/png/t_vec_broadcast.png\" style=\"max-width:70%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55402135-197e-4989-aed7-6c1adb452da8",
   "metadata": {},
   "source": [
    "### Inner loop body\n",
    "\n",
    "The inner loop of our kernel is as follows:\n",
    "```c++\n",
    "    uint16_t loop_count = (nbytes) >> 6;  \n",
    "    for(int j=0; j<loop_count; j++) {\n",
    "        \n",
    "        // Vector load pixels and mask\n",
    "        input_pixels = ::aie::load_v<vector_lanes>(in_buffer); \n",
    "        \n",
    "        // Create 64-bit threshold status register\n",
    "        ::aie::mask<64> threshold_status;\n",
    "        // Capture Boolean results of thresholding\n",
    "        threshold_status = ::aie::lt(threshold_vector, input_pixels);\n",
    "        \n",
    "        // Vector select actual pixel values using threshold_status as mask\n",
    "        output_pixels = ::aie::select(zeros_vector, saturation_vector, threshold_status);\n",
    "        // Vector store thresholded pixels in output buffer\n",
    "        ::aie::store_v(out_buffer, output_pixels);   \n",
    "        \n",
    "        // Advance buffer pointers by vectorization factor\n",
    "        in_buffer += vector_lanes;\n",
    "        out_buffer += vector_lanes;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6d1cd",
   "metadata": {},
   "source": [
    "#### Setup the loop counter and load input data\n",
    "\n",
    "The first thing to notice about the inner loop is that the bounds have changed; we can see that it has been divided by 64 with the `loop_count = nbytes >>6;` as we are processing 64 lanes in parallel in our vector operations. \n",
    "\n",
    "Inside the loop, we load into the input_pixels vector. A vector of 64-element is loaded from the input data buffer into `input_pixels` vector, based on the current location that `in_buffer` is pointing to, our input buffer pointer.\n",
    "\n",
    "```c++\n",
    "    input_pixels = ::aie::load_v<vector_lanes>(in_buffer); \n",
    "```\n",
    "\n",
    "Notice we use the `::aie::load_v()` vector load function. This is equivalent to reading a pointer in standard C, except doing this in C would require doing this 64 times for 8-bit types, or 16 times for 32-bit types. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935e70f-a00a-42bf-971d-4b01546974ce",
   "metadata": {},
   "source": [
    "#### Compare input vector against threshold and generate a mask\n",
    "\n",
    "Next, we declare a 64-bit `threshold_status` mask. In the following line we use the `aie::lt()` which is a *less than* vector operation. Perform an element-wise less than operation between our new input vector `input_pixels` and the threshold vector `threshold_vector` we made in the initialization step to produce a 64-element mask vector.\n",
    "If the comparison is true, a 1 is written, or a 0 if the comparison is false. \n",
    "\n",
    "```c++\n",
    "    ::aie::mask<64> threshold_status;\n",
    "    \n",
    "    threshold_status = ::aie::lt(threshold_vector, input_pixels);\n",
    "```\n",
    "\n",
    "Both these operations are shown visually below:\n",
    "\n",
    "<center><img src=\"./images/png/vec_gt_mask.png\" style=\"max-height: 400px; width:auto; height:auto;\"></center>\n",
    "<center><strong>Loading and thresholding 16 RGBA pixels</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f89056-a6ec-4e42-bc11-9c37f4ddd0eb",
   "metadata": {},
   "source": [
    "Once we have a mask of the element-wise comparisons between our vector and our threshold values, we use it to select for the RGB channels of each pixel whether to set it to zero or to set it to the maximum value. The following lines from the inner loop above achieve this:\n",
    "\n",
    "```c++\n",
    "        output_pixels = ::aie::select(zeros_vector, saturation_vector, threshold_status);\n",
    "```\n",
    "\n",
    "<center><img src=\"./images/png/select_vec_store_v.png\" style=\"max-height: 550px; width:auto; height:auto;\"></center>\n",
    "<center><strong>Selecting and writing 16 RGBA pixels</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6f1c8-f5b6-4586-9ca5-1c65fd654ad1",
   "metadata": {},
   "source": [
    "The output vector can then be written back to the output data memory buffer using `::aie::store_v()`\n",
    "\n",
    "```c++\n",
    "    ::aie::store_v(out_buffer, output_pixels);   \n",
    "```\n",
    "\n",
    "The last step is to increment the input and output pointers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5f61d",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9eb2a",
   "metadata": {},
   "source": [
    "## Build the Application\n",
    "\n",
    "Let us build and run this new vectorized version and see if we get a smoother response in the output. \n",
    "\n",
    "**Run the cell below to build the application.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301edbda-f053-4699-8cb4-9bcd160d84fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:13:30.490546Z",
     "iopub.status.busy": "2023-12-19T15:13:30.490546Z",
     "iopub.status.idle": "2023-12-19T15:14:00.423575Z",
     "shell.execute_reply": "2023-12-19T15:14:00.423575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached threshold_vec kernel object file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the xclbin...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Building Application... threshold_vec.xclbin & threshold_vec.seq delivered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from npu.lib.graphs.graph_1ct import RGB720pBuilder\n",
    "\n",
    "img_in = np.zeros(shape=(720,1280, 4), dtype=np.uint8)\n",
    "img_out = np.zeros(shape=(720,1280, 4), dtype=np.uint8)\n",
    "\n",
    "app_builder = RGB720pBuilder(kernel=threshold_vec)\n",
    "app_builder.build(img_in, img_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c7f93",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a5309-3e34-48aa-9e0e-7eed51beaa25",
   "metadata": {},
   "source": [
    "## Run the Application\n",
    "\n",
    "Now that our application is built, let us look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3a72d0-fa9e-4a9f-bcfd-9d20fbb78800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:14:00.423575Z",
     "iopub.status.busy": "2023-12-19T15:14:00.423575Z",
     "iopub.status.idle": "2023-12-19T15:14:00.439624Z",
     "shell.execute_reply": "2023-12-19T15:14:00.439624Z"
    }
   },
   "outputs": [],
   "source": [
    "from npu.lib.graphs.image_looper_720p import ImageLooper720p\n",
    "\n",
    "app = ImageLooper720p(img='images/jpg/ryzenai_future_starts_now.jpg', \n",
    "                      xclbin='threshold_vec.xclbin', \n",
    "                      rtps={\"r_threshold\" : { \"type\": \"slider\", \"value\": 0, \"min\": 0, \"max\" : 255},\n",
    "                            \"g_threshold\" : { \"type\": \"slider\", \"min\": 0, \"max\" : 255},\n",
    "                            \"b_threshold\" : { \"type\": \"slider\", \"min\": 0, \"max\" : 255}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74738af1-80db-462d-a1f5-500d2a32cfdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:14:00.439624Z",
     "iopub.status.busy": "2023-12-19T15:14:00.439624Z",
     "iopub.status.idle": "2023-12-19T15:14:00.740351Z",
     "shell.execute_reply": "2023-12-19T15:14:00.740351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59f84461ea8400b97348fede60316de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b14eeb6dcf498490e3c2bc683b028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbe826f8085459c83cb1571ca3f38f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=128, description='r_threshold', max=255, style=SliderStyle(description_width='a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231487b-cafb-4b60-b70b-a863dc810802",
   "metadata": {},
   "source": [
    "The response to changes in the RTPs are now much smoother thanks to vectorizing the kernel.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"info\">\n",
    "    Vectorization help us achieve real-time performance for this video processing application.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ec4b9",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a812d2",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next notebook we will learn how to use the `AppBuilder` class to create your own custom dataflow graph that can run in the NPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee6fed-ed8a-4349-8924-6c1d04b266c2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "Copyright&copy; 2023 AMD, Inc\n",
    "</center>\n",
    "<center>\n",
    "SPDX-License-Identifier: MIT\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08806dbb162b415d947eeb1cf15f259c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": "auto",
       "handle_color": null
      }
     },
     "0b8af922c1c0492dbe3c766e0d3540a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "IntSliderView",
       "behavior": "drag-tap",
       "continuous_update": true,
       "description": "b_threshold",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_32cf6a1f3f39435db690d879f35ddf3a",
       "max": 255,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_d122c8dda75b4be1ab8e75e0e56bd579",
       "tabbable": null,
       "tooltip": null,
       "value": 128
      }
     },
     "2f2336b181c740b4a707160d4339d310": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32cf6a1f3f39435db690d879f35ddf3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3cbe826f8085459c83cb1571ca3f38f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d3d9f51aba9f4ada96b4514ef63c5ee7",
        "IPY_MODEL_fad9b64266864a16aa7ad7cc734a4884",
        "IPY_MODEL_0b8af922c1c0492dbe3c766e0d3540a0"
       ],
       "layout": "IPY_MODEL_baecd7ed94524920b0fd6c329f526a7f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "47e90cfcbf284ebabdade8e944c15aa8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e1b3d13f65143a7a7ca8ecd22476fa0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "917f5afa89eb4c2aaad38e93b717d3e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "baecd7ed94524920b0fd6c329f526a7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c8909e7e695445108922bebd939921e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": "auto",
       "handle_color": null
      }
     },
     "d122c8dda75b4be1ab8e75e0e56bd579": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": "auto",
       "handle_color": null
      }
     },
     "d3d9f51aba9f4ada96b4514ef63c5ee7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "IntSliderView",
       "behavior": "drag-tap",
       "continuous_update": true,
       "description": "r_threshold",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_2f2336b181c740b4a707160d4339d310",
       "max": 255,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_c8909e7e695445108922bebd939921e5",
       "tabbable": null,
       "tooltip": null,
       "value": 128
      }
     },
     "d4b14eeb6dcf498490e3c2bc683b028f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "Stop",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_7e1b3d13f65143a7a7ca8ecd22476fa0",
       "style": "IPY_MODEL_917f5afa89eb4c2aaad38e93b717d3e2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "df5de2a519ae42769be2f2768510ba90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e59f84461ea8400b97348fede60316de": {
      "buffers": [
       {
        "data": "",
        "encoding": "base64",
        "path": [
         "value"
        ]
       }
      ],
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ImageModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ImageModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ImageView",
       "format": "jpeg",
       "height": "",
       "layout": "IPY_MODEL_47e90cfcbf284ebabdade8e944c15aa8",
       "tabbable": null,
       "tooltip": null,
       "width": ""
      }
     },
     "fad9b64266864a16aa7ad7cc734a4884": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "IntSliderView",
       "behavior": "drag-tap",
       "continuous_update": true,
       "description": "g_threshold",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_df5de2a519ae42769be2f2768510ba90",
       "max": 255,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_08806dbb162b415d947eeb1cf15f259c",
       "tabbable": null,
       "tooltip": null,
       "value": 128
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
